{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024f310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e73a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/applications/\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "#freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d600bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model):\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.1)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    #x = keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(231, activation='softmax')(x)\n",
    "    #x = keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # and a logistic layer\n",
    "    #predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bbd1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(N, num_classes):\n",
    "\n",
    "    #Declaring array of images \n",
    "    images = []\n",
    "\n",
    "    #loop to import images from file directory\n",
    "    for i in range (12): \n",
    "        x = np.asarray(Image.open(\"C:/Users/Mark Fahy/Desktop/Final Year/Final Year Project/bongard-problems-master/bongard-problems-master/p\"+str(N)+\"/\"+str(i)+\".png\").convert('L'))\n",
    "        x = np.array((x, x, x))\n",
    "        #print(x.shape)\n",
    "        images.append(x)\n",
    "        \n",
    "    #np.tile(images, 3)\n",
    "    #Converting to numpy array\n",
    "    dataset = np.array(images)\n",
    "    dataset = dataset.reshape((-1, 104, 104, 3))    \n",
    "\n",
    "    #Y data\n",
    "    yvalues = (0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)\n",
    "    \n",
    "    # Scale images to the [0, 1] range\n",
    "    dataset = dataset.astype(\"float32\") / 255\n",
    "    \n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    yvalues = keras.utils.to_categorical(yvalues, num_classes)    \n",
    "    \n",
    "    return dataset, yvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf2bcc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 231)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "losses = []\n",
    "folds = 0\n",
    "problems = 0\n",
    "\n",
    "global_x_train = []\n",
    "global_x_test = []\n",
    "global_y_train = []\n",
    "global_y_test = []\n",
    "\n",
    "num_classes = 231\n",
    "#input_shape = (104, 104, 1)\n",
    "\n",
    "for i in range (1, 232): \n",
    "    dataset, yvalues = read_images(i, num_classes)\n",
    "    #problems = problems + 1\n",
    "    #print(\"Problem number: \", problems)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, yvalues, test_size=0.16666)  \n",
    "    y_train = np.ones_like(y_train) * (i - 1)\n",
    "    y_test = np.ones_like(y_test) * (i - 1)\n",
    "\n",
    "    \n",
    "    global_x_train.extend(x_train)\n",
    "    global_x_test.extend(x_test)\n",
    "    global_y_train.extend(y_train)\n",
    "    global_y_test.extend(y_test)\n",
    "    \n",
    "global_x_train = np.array(global_x_train)\n",
    "global_x_test = np.array(global_x_test)\n",
    "global_y_train = np.array(global_y_train)\n",
    "global_y_test = np.array(global_y_test)\n",
    "\n",
    "\n",
    "#convert class vectors to binary class matrices\n",
    "global_y_test = keras.utils.to_categorical(global_y_test, num_classes) \n",
    "global_y_train = keras.utils.to_categorical(global_y_train, num_classes) \n",
    "\n",
    "print(global_y_test.shape)\n",
    "print(global_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da0bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "73/73 [==============================] - 21s 238ms/step - loss: 5.4574 - accuracy: 0.0152 - val_loss: 5.3010 - val_accuracy: 0.0303\n",
      "Epoch 2/28\n",
      "73/73 [==============================] - 20s 273ms/step - loss: 5.0458 - accuracy: 0.0485 - val_loss: 4.9430 - val_accuracy: 0.0519\n",
      "Epoch 3/28\n",
      "73/73 [==============================] - 20s 277ms/step - loss: 4.3828 - accuracy: 0.1195 - val_loss: 4.6407 - val_accuracy: 0.0844\n",
      "Epoch 4/28\n",
      "73/73 [==============================] - 20s 278ms/step - loss: 3.7931 - accuracy: 0.1957 - val_loss: 4.3732 - val_accuracy: 0.1234\n",
      "Epoch 5/28\n",
      "73/73 [==============================] - 21s 282ms/step - loss: 3.2960 - accuracy: 0.2641 - val_loss: 4.3624 - val_accuracy: 0.1039\n",
      "Epoch 6/28\n",
      "73/73 [==============================] - 21s 288ms/step - loss: 2.9456 - accuracy: 0.3216 - val_loss: 4.2913 - val_accuracy: 0.1515\n",
      "Epoch 7/28\n",
      "73/73 [==============================] - 21s 292ms/step - loss: 2.6255 - accuracy: 0.3900 - val_loss: 4.3716 - val_accuracy: 0.1515\n",
      "Epoch 8/28\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 2.3527 - accuracy: 0.4385 - val_loss: 4.3058 - val_accuracy: 0.1558\n",
      "Epoch 9/28\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 2.1073 - accuracy: 0.4736 - val_loss: 4.3152 - val_accuracy: 0.1580\n",
      "Epoch 10/28\n",
      "73/73 [==============================] - 22s 308ms/step - loss: 1.9109 - accuracy: 0.5299 - val_loss: 4.3475 - val_accuracy: 0.1667\n",
      "Epoch 11/28\n",
      "73/73 [==============================] - 22s 302ms/step - loss: 1.7021 - accuracy: 0.5870 - val_loss: 4.4512 - val_accuracy: 0.1667\n",
      "Epoch 12/28\n",
      "73/73 [==============================] - 22s 300ms/step - loss: 1.5020 - accuracy: 0.6281 - val_loss: 4.5064 - val_accuracy: 0.1905\n",
      "Epoch 13/28\n",
      "73/73 [==============================] - 22s 309ms/step - loss: 1.3679 - accuracy: 0.6532 - val_loss: 4.4284 - val_accuracy: 0.1472\n",
      "Epoch 14/28\n",
      "73/73 [==============================] - 22s 300ms/step - loss: 1.2178 - accuracy: 0.6952 - val_loss: 4.6180 - val_accuracy: 0.1602\n",
      "Epoch 15/28\n",
      "73/73 [==============================] - 22s 301ms/step - loss: 1.0845 - accuracy: 0.7221 - val_loss: 4.6039 - val_accuracy: 0.1948\n",
      "Epoch 16/28\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.9638 - accuracy: 0.7632 - val_loss: 4.8065 - val_accuracy: 0.1905\n",
      "Epoch 17/28\n",
      "73/73 [==============================] - 22s 300ms/step - loss: 0.8515 - accuracy: 0.7831 - val_loss: 4.8664 - val_accuracy: 0.1688\n",
      "Epoch 18/28\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.7654 - accuracy: 0.8156 - val_loss: 5.3657 - val_accuracy: 0.1515\n",
      "Epoch 19/28\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.6789 - accuracy: 0.8329 - val_loss: 5.1883 - val_accuracy: 0.1688\n",
      "Epoch 20/28\n",
      "73/73 [==============================] - 23s 315ms/step - loss: 0.5947 - accuracy: 0.8576 - val_loss: 5.0121 - val_accuracy: 0.1970\n",
      "Epoch 21/28\n",
      "73/73 [==============================] - 22s 295ms/step - loss: 0.5252 - accuracy: 0.8753 - val_loss: 5.0516 - val_accuracy: 0.1797\n",
      "Epoch 22/28\n",
      "73/73 [==============================] - 22s 300ms/step - loss: 0.4745 - accuracy: 0.8857 - val_loss: 5.4796 - val_accuracy: 0.1818\n",
      "Epoch 23/28\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.4255 - accuracy: 0.8952 - val_loss: 5.6500 - val_accuracy: 0.1732\n",
      "Epoch 24/28\n",
      "73/73 [==============================] - 23s 310ms/step - loss: 0.3687 - accuracy: 0.9087 - val_loss: 5.6848 - val_accuracy: 0.1667\n",
      "Epoch 25/28\n",
      "73/73 [==============================] - 22s 299ms/step - loss: 0.3434 - accuracy: 0.9108 - val_loss: 5.8132 - val_accuracy: 0.1970\n",
      "Epoch 26/28\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 0.2891 - accuracy: 0.9364 - val_loss: 6.0519 - val_accuracy: 0.1775\n",
      "Epoch 27/28\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 0.2537 - accuracy: 0.9420 - val_loss: 5.6841 - val_accuracy: 0.2013\n",
      "Epoch 28/28\n",
      "73/73 [==============================] - 22s 300ms/step - loss: 0.2485 - accuracy: 0.9433 - val_loss: 5.7972 - val_accuracy: 0.1905\n",
      "Accuracy:  0.190476194024086\n",
      "Loss:  5.797183990478516\n"
     ]
    }
   ],
   "source": [
    "model = create_model(base_model)   \n",
    "    \n",
    "model.fit(global_x_train, global_y_train, epochs = 28, validation_data = (global_x_test, global_y_test))\n",
    "score = model.evaluate(global_x_test, global_y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', score[1])\n",
    "print('Loss: ', score[0])\n",
    "    \n",
    "\n",
    "#print(\"Average Accuracy: \", (sum(accuracies) / len(accuracies)) )\n",
    "#print(\"Average Loss: \", (sum(losses) / len(losses)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2f568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "#freeze all convolutional layers\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69129aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.0756 - accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7022 - accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2250 - accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2328 - accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0916 - accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9886 - accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4587 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5205 - accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7484 - accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4544 - accuracy: 0.8000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1303, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_82\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 100)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARKFA~1\\AppData\\Local\\Temp/ipykernel_21200/581122340.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PythonEnvs\\KerasEg\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\training.py\", line 1303, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\PythonEnvs\\KerasEg\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 227, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_82\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 100)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "t_accuracies = []\n",
    "num_classes = 2\n",
    "problems = 0\n",
    "\n",
    "\n",
    "for i in range (1, 21): \n",
    "    dataset, yvalues = read_images(i, num_classes)    \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, yvalues, test_size=0.16666)\n",
    "    x_train_emb = new_model.predict(x_train)\n",
    "    x_test_emb = new_model.predict(x_test)\n",
    "    \n",
    "    x = new_model.output\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    LR_model = Model(inputs=new_model.input, outputs=x)    \n",
    "    LR_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "        \n",
    "    LR_model.fit(x_train, y_train, epochs = 10)\n",
    "    score = LR_model.evaluate(x_test_emb, y_test, verbose=0) \n",
    "    \n",
    "    accuracies.append(score[1])\n",
    "    losses.append(score[0])\n",
    "    problems += 1\n",
    "    print(\"P No: \", problems)\n",
    "        \n",
    "        \n",
    "print(accuracies)\n",
    "print(losses)\n",
    "\n",
    "print(\"Average Accuracy: \", (sum(accuracies) / len(accuracies)) )\n",
    "print(\"Average Loss: \", (sum(losses) / len(losses)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ef9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasEg",
   "language": "python",
   "name": "keraseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
