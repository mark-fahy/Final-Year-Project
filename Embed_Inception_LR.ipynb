{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024f310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e73a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/applications/\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "#freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d600bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model):\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.1)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    #x = keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(231, activation='softmax')(x)\n",
    "    #x = keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # and a logistic layer\n",
    "    #predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbd1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(N, num_classes):\n",
    "\n",
    "    #Declaring array of images \n",
    "    images = []\n",
    "\n",
    "    #loop to import images from file directory\n",
    "    for i in range (12): \n",
    "        x = np.asarray(Image.open(\"C:/Users/Mark Fahy/Desktop/Final Year/Final Year Project/bongard-problems-master/bongard-problems-master/p\"+str(N)+\"/\"+str(i)+\".png\").convert('L'))\n",
    "        x = np.array((x, x, x))\n",
    "        #print(x.shape)\n",
    "        images.append(x)\n",
    "        \n",
    "    #np.tile(images, 3)\n",
    "    #Converting to numpy array\n",
    "    dataset = np.array(images)\n",
    "    dataset = dataset.reshape((-1, 104, 104, 3))    \n",
    "\n",
    "    #Y data\n",
    "    yvalues = (0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)\n",
    "    \n",
    "    # Scale images to the [0, 1] range\n",
    "    dataset = dataset.astype(\"float32\") / 255\n",
    "    \n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    #yvalues = keras.utils.to_categorical(yvalues, num_classes)    \n",
    "    \n",
    "    return dataset, yvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf2bcc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 231)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "losses = []\n",
    "folds = 0\n",
    "problems = 0\n",
    "\n",
    "global_x_train = []\n",
    "global_x_test = []\n",
    "global_y_train = []\n",
    "global_y_test = []\n",
    "\n",
    "num_classes = 231\n",
    "#input_shape = (104, 104, 1)\n",
    "\n",
    "for i in range (1, 232): \n",
    "    dataset, yvalues = read_images(i, num_classes)\n",
    "    #problems = problems + 1\n",
    "    #print(\"Problem number: \", problems)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset, yvalues, test_size=0.16666)  \n",
    "    y_train = np.ones_like(y_train) * (i - 1)\n",
    "    y_test = np.ones_like(y_test) * (i - 1)\n",
    "\n",
    "    \n",
    "    global_x_train.extend(x_train)\n",
    "    global_x_test.extend(x_test)\n",
    "    global_y_train.extend(y_train)\n",
    "    global_y_test.extend(y_test)\n",
    "    \n",
    "global_x_train = np.array(global_x_train)\n",
    "global_x_test = np.array(global_x_test)\n",
    "global_y_train = np.array(global_y_train)\n",
    "global_y_test = np.array(global_y_test)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "global_y_test = keras.utils.to_categorical(global_y_test, num_classes) \n",
    "global_y_train = keras.utils.to_categorical(global_y_train, num_classes) \n",
    "\n",
    "print(global_y_test.shape)\n",
    "print(global_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da0bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 19s 210ms/step - loss: 5.4484 - accuracy: 0.0121 - val_loss: 5.4013 - val_accuracy: 0.0130\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 20s 276ms/step - loss: 5.0437 - accuracy: 0.0481 - val_loss: 4.9557 - val_accuracy: 0.0541\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 20s 280ms/step - loss: 4.3920 - accuracy: 0.1182 - val_loss: 4.5342 - val_accuracy: 0.0866\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 21s 283ms/step - loss: 3.8004 - accuracy: 0.1827 - val_loss: 4.3146 - val_accuracy: 0.1126\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 21s 287ms/step - loss: 3.3252 - accuracy: 0.2619 - val_loss: 4.2809 - val_accuracy: 0.1255\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 21s 293ms/step - loss: 2.9461 - accuracy: 0.3182 - val_loss: 4.2344 - val_accuracy: 0.1299\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 22s 301ms/step - loss: 2.6431 - accuracy: 0.3645 - val_loss: 4.1879 - val_accuracy: 0.1342\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 22s 301ms/step - loss: 2.3453 - accuracy: 0.4277 - val_loss: 4.2406 - val_accuracy: 0.1407\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 2.1371 - accuracy: 0.4784 - val_loss: 4.1783 - val_accuracy: 0.1580\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 22s 297ms/step - loss: 1.8914 - accuracy: 0.5273 - val_loss: 4.2243 - val_accuracy: 0.1623\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 22s 302ms/step - loss: 1.7297 - accuracy: 0.5701 - val_loss: 4.2313 - val_accuracy: 0.1818\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 1.5471 - accuracy: 0.6100 - val_loss: 4.3470 - val_accuracy: 0.1580\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 22s 298ms/step - loss: 1.4061 - accuracy: 0.6463 - val_loss: 4.5284 - val_accuracy: 0.1623\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 22s 305ms/step - loss: 1.2336 - accuracy: 0.6939 - val_loss: 4.5847 - val_accuracy: 0.1861\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 1.1138 - accuracy: 0.7091 - val_loss: 4.4461 - val_accuracy: 0.1818\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 22s 298ms/step - loss: 1.0096 - accuracy: 0.7294 - val_loss: 4.5626 - val_accuracy: 0.1753\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 24s 333ms/step - loss: 0.8860 - accuracy: 0.7810 - val_loss: 4.6447 - val_accuracy: 0.2100\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 22s 298ms/step - loss: 0.7865 - accuracy: 0.8009 - val_loss: 4.7066 - val_accuracy: 0.1926\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 22s 301ms/step - loss: 0.7084 - accuracy: 0.8286 - val_loss: 4.8526 - val_accuracy: 0.1905\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.6156 - accuracy: 0.8567 - val_loss: 5.0205 - val_accuracy: 0.1667\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 22s 296ms/step - loss: 0.5632 - accuracy: 0.8589 - val_loss: 5.1328 - val_accuracy: 0.1926\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 22s 302ms/step - loss: 0.5051 - accuracy: 0.8779 - val_loss: 5.0286 - val_accuracy: 0.2186\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 23s 311ms/step - loss: 0.4594 - accuracy: 0.8887 - val_loss: 5.1821 - val_accuracy: 0.1818\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 23s 318ms/step - loss: 0.4006 - accuracy: 0.9104 - val_loss: 5.1118 - val_accuracy: 0.2056\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 22s 304ms/step - loss: 0.3606 - accuracy: 0.9130 - val_loss: 5.5041 - val_accuracy: 0.1840\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 23s 312ms/step - loss: 0.3236 - accuracy: 0.9346 - val_loss: 5.5991 - val_accuracy: 0.1883\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 23s 312ms/step - loss: 0.2816 - accuracy: 0.9368 - val_loss: 5.6800 - val_accuracy: 0.1775\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 22s 308ms/step - loss: 0.2657 - accuracy: 0.9437 - val_loss: 5.7931 - val_accuracy: 0.1753\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 25s 347ms/step - loss: 0.2412 - accuracy: 0.9437 - val_loss: 5.7770 - val_accuracy: 0.1861\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 23s 310ms/step - loss: 0.2316 - accuracy: 0.9468 - val_loss: 5.7654 - val_accuracy: 0.1970\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 23s 312ms/step - loss: 0.1977 - accuracy: 0.9567 - val_loss: 6.1959 - val_accuracy: 0.1732\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 23s 317ms/step - loss: 0.1798 - accuracy: 0.9632 - val_loss: 6.0921 - val_accuracy: 0.1905\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 24s 327ms/step - loss: 0.1675 - accuracy: 0.9671 - val_loss: 6.2142 - val_accuracy: 0.1991\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 23s 317ms/step - loss: 0.1595 - accuracy: 0.9619 - val_loss: 6.3508 - val_accuracy: 0.1905\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 24s 325ms/step - loss: 0.1388 - accuracy: 0.9732 - val_loss: 6.2363 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 24s 324ms/step - loss: 0.1332 - accuracy: 0.9714 - val_loss: 6.9740 - val_accuracy: 0.1883\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 23s 316ms/step - loss: 0.1264 - accuracy: 0.9714 - val_loss: 6.9668 - val_accuracy: 0.1797\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 24s 327ms/step - loss: 0.1129 - accuracy: 0.9766 - val_loss: 6.6037 - val_accuracy: 0.1926\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 23s 316ms/step - loss: 0.1008 - accuracy: 0.9775 - val_loss: 6.8749 - val_accuracy: 0.1970\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 25s 343ms/step - loss: 0.0943 - accuracy: 0.9775 - val_loss: 6.9788 - val_accuracy: 0.1883\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 24s 324ms/step - loss: 0.0941 - accuracy: 0.9775 - val_loss: 7.1154 - val_accuracy: 0.2121\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 23s 315ms/step - loss: 0.1014 - accuracy: 0.9736 - val_loss: 7.0573 - val_accuracy: 0.1883\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 24s 326ms/step - loss: 0.0801 - accuracy: 0.9823 - val_loss: 7.3120 - val_accuracy: 0.1775\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 23s 316ms/step - loss: 0.0968 - accuracy: 0.9736 - val_loss: 6.9652 - val_accuracy: 0.1970\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 0.0780 - accuracy: 0.9831 - val_loss: 6.8699 - val_accuracy: 0.1948\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 24s 328ms/step - loss: 0.0736 - accuracy: 0.9840 - val_loss: 7.2556 - val_accuracy: 0.1926\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 25s 340ms/step - loss: 0.0715 - accuracy: 0.9870 - val_loss: 7.3113 - val_accuracy: 0.1926\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 24s 327ms/step - loss: 0.0603 - accuracy: 0.9874 - val_loss: 7.2760 - val_accuracy: 0.2056\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 23s 317ms/step - loss: 0.0656 - accuracy: 0.9879 - val_loss: 7.4171 - val_accuracy: 0.2078\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 0.0665 - accuracy: 0.9844 - val_loss: 7.7022 - val_accuracy: 0.1905\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 24s 332ms/step - loss: 0.0616 - accuracy: 0.9835 - val_loss: 7.6143 - val_accuracy: 0.1970\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 25s 343ms/step - loss: 0.0640 - accuracy: 0.9853 - val_loss: 7.5823 - val_accuracy: 0.1905\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 24s 329ms/step - loss: 0.0634 - accuracy: 0.9823 - val_loss: 7.6234 - val_accuracy: 0.2056\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 27s 370ms/step - loss: 0.0532 - accuracy: 0.9857 - val_loss: 7.9268 - val_accuracy: 0.1905\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 25s 341ms/step - loss: 0.0614 - accuracy: 0.9827 - val_loss: 7.9958 - val_accuracy: 0.1970\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 24s 331ms/step - loss: 0.0494 - accuracy: 0.9892 - val_loss: 7.9200 - val_accuracy: 0.1970\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 24s 326ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 8.3107 - val_accuracy: 0.1883\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 24s 326ms/step - loss: 0.0562 - accuracy: 0.9879 - val_loss: 7.8542 - val_accuracy: 0.1926\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 24s 332ms/step - loss: 0.0457 - accuracy: 0.9879 - val_loss: 8.2442 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 25s 346ms/step - loss: 0.0463 - accuracy: 0.9883 - val_loss: 8.5110 - val_accuracy: 0.1991\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 25s 345ms/step - loss: 0.0458 - accuracy: 0.9909 - val_loss: 8.4789 - val_accuracy: 0.2100\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 26s 352ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 8.5257 - val_accuracy: 0.1861\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 24s 325ms/step - loss: 0.0390 - accuracy: 0.9905 - val_loss: 8.5787 - val_accuracy: 0.2035\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 25s 338ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 8.6282 - val_accuracy: 0.2035\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 25s 349ms/step - loss: 0.0393 - accuracy: 0.9913 - val_loss: 8.6031 - val_accuracy: 0.1905\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 25s 347ms/step - loss: 0.0471 - accuracy: 0.9879 - val_loss: 8.6184 - val_accuracy: 0.2121\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 25s 338ms/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 8.8087 - val_accuracy: 0.1905\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 24s 329ms/step - loss: 0.0334 - accuracy: 0.9922 - val_loss: 8.8872 - val_accuracy: 0.1905\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 25s 342ms/step - loss: 0.0435 - accuracy: 0.9879 - val_loss: 8.8735 - val_accuracy: 0.2035\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 24s 326ms/step - loss: 0.0349 - accuracy: 0.9918 - val_loss: 8.9181 - val_accuracy: 0.1991\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 24s 333ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 9.0235 - val_accuracy: 0.1905\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 25s 338ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 9.2932 - val_accuracy: 0.1861\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 24s 332ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 9.1281 - val_accuracy: 0.1861\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 25s 338ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 9.2624 - val_accuracy: 0.1840\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 26s 351ms/step - loss: 0.0398 - accuracy: 0.9883 - val_loss: 9.1967 - val_accuracy: 0.1926\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 25s 339ms/step - loss: 0.0331 - accuracy: 0.9922 - val_loss: 9.1964 - val_accuracy: 0.2035\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 24s 329ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 9.3333 - val_accuracy: 0.2035\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 24s 332ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 9.7232 - val_accuracy: 0.2100\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 25s 340ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 9.4513 - val_accuracy: 0.1840\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 26s 354ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 9.3707 - val_accuracy: 0.1970\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 26s 355ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 9.6631 - val_accuracy: 0.2165\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 24s 327ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 9.3520 - val_accuracy: 0.2165\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 24s 333ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 9.6164 - val_accuracy: 0.2013\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 25s 343ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 9.8787 - val_accuracy: 0.2078\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 26s 351ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 10.0348 - val_accuracy: 0.1775\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 24s 336ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 10.1740 - val_accuracy: 0.1991\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 26s 354ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 9.7708 - val_accuracy: 0.1948\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 25s 340ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 9.7821 - val_accuracy: 0.2013\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 25s 350ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 10.0932 - val_accuracy: 0.1926\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 25s 347ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 9.8546 - val_accuracy: 0.1948\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 25s 347ms/step - loss: 0.0455 - accuracy: 0.9874 - val_loss: 9.9309 - val_accuracy: 0.2121\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 26s 356ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 10.1794 - val_accuracy: 0.2035\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 25s 339ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 10.0825 - val_accuracy: 0.1948\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 27s 371ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 10.5188 - val_accuracy: 0.1861\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 25s 343ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 10.2609 - val_accuracy: 0.2229\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 25s 347ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 10.6550 - val_accuracy: 0.1861\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 26s 351ms/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 10.5861 - val_accuracy: 0.2100\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 25s 341ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 10.4257 - val_accuracy: 0.1991\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 26s 355ms/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 10.4105 - val_accuracy: 0.2100\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 25s 339ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 10.4955 - val_accuracy: 0.2121\n",
      "Accuracy:  0.21212121844291687\n",
      "Loss:  10.495499610900879\n"
     ]
    }
   ],
   "source": [
    "model = create_model(base_model)   \n",
    "    \n",
    "model.fit(global_x_train, global_y_train, epochs = 100, validation_data = (global_x_test, global_y_test))\n",
    "score = model.evaluate(global_x_test, global_y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', score[1])\n",
    "print('Loss: ', score[0])\n",
    "    \n",
    "\n",
    "#print(\"Average Accuracy: \", (sum(accuracies) / len(accuracies)) )\n",
    "#print(\"Average Loss: \", (sum(losses) / len(losses)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025a6f7",
   "metadata": {},
   "source": [
    "From running 100 epochs above, the trend shows that anything more than 25-30 epochs is a repitive pattern where the valdtaion accuracy floats between ~0.22 and ~0.18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f568d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasEg",
   "language": "python",
   "name": "keraseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
